%==============================================================================
\section{Concurrent GLP}
\label{sec:glp}
%==============================================================================

This section presents Grassroots Logic Programs (GLP), a concurrent logic programming language. We begin with transition systems, recall logic programs (LP) and define their operational semantics via transition systems, and then extend LP to GLP. We illustrate GLP with programming examples and conclude with the grassroots social graph---the foundational platform that all other grassroots platforms build upon.

%------------------------------------------------------------------------------
\subsection{Transition Systems}
\label{sec:ts}
%------------------------------------------------------------------------------

\begin{definition}[Transition System]
\label{def:ts}
A \temph{transition system} is a tuple $TS = (C, c_0, T)$ where $C$ is an arbitrary set of \temph{configurations}, $c_0 \in C$ is a designated \temph{initial configuration}, and $T \subseteq C \times C$ is a \temph{transition relation}, with transitions written $c \rightarrow c' \in T$.
A transition $c \rightarrow c' \in T$ is \temph{enabled} from configuration $c$. A configuration $c$ is \temph{terminal} if no transitions are enabled from $c$. A \temph{computation} is a (finite or infinite) sequence of configurations where for each two consecutive configurations $(c,c')$ in the sequence, $c \rightarrow c' \in T$. A \temph{run} is a computation starting from $c_0$, which is \temph{complete} if it is infinite or ends in a terminal configuration.
\end{definition}

%------------------------------------------------------------------------------
\subsection{Logic Programs}
\label{sec:lp-ts}
%------------------------------------------------------------------------------

We recall standard Logic Programs (LP) notions of syntax, most-general unifier (mgu), and semantics via goal reduction.

\begin{definition}[Logic Programs Syntax]
\label{def:lp-syntax}
We employ standard LP notions. Let $\calV$ denote the set of \temph{variables} (identifiers beginning with uppercase). A \temph{term} is a variable, a constant (numbers, strings, or the empty list \verb|[]|), or a compound term $f(T_1,\ldots,T_n)$ with functor $f$ and subterms $T_i$. Let $\calT$ denote the set of all terms. We use standard list notation: \verb=[X|Xs]= for a list cell, \verb|[X1,...,Xn]| for finite lists. A term is \temph{ground} if it contains no variables.

A \temph{unit goal} is a compound term, also commonly referred to as an \temph{atom}. A \temph{goal} is a multiset of unit goals; the empty goal is written \verb|true|. A \temph{clause} $A$~\verb|:-|~$B$ has head $A$ (a unit goal) and body $B$ (a goal); a \temph{unit clause} has empty body. A \temph{logic program} is a finite set of clauses; clauses for the same predicate form a \temph{procedure}. Let $\calG(P)$ denote the set of goals over the vocabulary of the program $P$.
\end{definition}

A \emph{substitution} $\sigma$ is an idempotent function $\sigma: \calV \to \calT$, a mapping from variables to terms applied to a fixed point. By convention, $\sigma(x)=x\sigma$. Let $\Sigma$ denote the set of all substitutions. We assume standard notions of instance, ground, renaming, renaming apart, unifier, and most-general unifier (mgu).

\begin{definition}[LP Goal/Clause Reduction]
\label{def:lp-reduction}
Given an LP unit goal $A$ and clause $C$, with $H$ \verb|:-| $B$ being the result of renaming $C$ apart from $A$, the \temph{LP reduction} of $A$ with $C$ \temph{succeeds with} $(B,\sigma)$ if $A$ and $H$ have an mgu $\sigma$.
\end{definition}

\begin{definition}[Logic Programs Transition System]
\label{def:lp-ts}
A transition system $LP(P) = (C, c_0, T)$ is a \temph{Logic Programs transition system} for a logic program $P$ and initial goal $G_0 \in \mathcal{G}(P)$, if $C=\mathcal{G}(P)\times \Sigma$, $c_0=(G_0,\emptyset)$, and $T$ is the set of all transitions $(G,\sigma) \rightarrow (G',\sigma')$ such that for some unit goal $A \in G$ and clause $C \in P$ the LP reduction of $A$ with $C$ succeeds with $(B,\hat\sigma)$, $G' = (G \setminus \{A\} \cup B)\hat\sigma$, and $\sigma'=\sigma\circ\hat\sigma$.
\end{definition}

LP has two forms of nondeterminism: the choice of $A \in G$, called \emph{and-nondeterminism}, and the choice of $C \in P$, called \emph{or-nondeterminism}, and as such are closely-related to Alternating Turing Machines~\cite{shapiro1984alternation}.

\begin{definition}[Proper and Successful Run, Outcome]
\label{def:proper-run}
A run $\rho: (G_0,\sigma_0) \rightarrow \cdots \rightarrow (G_n, \sigma_n)$ of $LP(P)$ is \temph{proper} if for any $1\le i< n$, a variable that occurs in $G_{i+1}$ but not in $G_i$ also does not occur in any $G_j$, $j<i$. If proper, the \temph{outcome} of $\rho$ is $(G_0$ \verb|:-| $G_n)\sigma_n$. Such a run is \temph{successful} if $G_n=\emptyset$.
\end{definition}
The following proposition justifies the computation-as-deduction view of LP~\cite{kowalski1974predicate},
calling a proper LP run a \emph{derivation} and a complete proper run ending in the empty goal a \emph{successful derivation}.

\begin{proposition}[LP Computation is Deduction]
\label{prop:lp-deduction}
The outcome $(G_0$ \verb|:-| $G_n)\sigma$ of a proper run of $LP(P)$ is a logical consequence of $P$.
\end{proposition}

\mypara{Denotational Semantics}
The $LP(P)$ transition system allows defining several denotational semantic notions for a program $P$: (1) the \emph{clause semantics} is the set of all outcomes of all proper runs with an initial most-general unit goal (arguments are distinct variables), closely related to the fully-abstract compositional semantics of LP~\cite{gaifman1989fully}; (2) the \emph{atom semantics} is the set of all outcomes of all successful derivations with an initial most-general unit goal; (3) the \emph{ground atom semantics} is the standard model-theoretic semantics, the set of ground instances of the atom semantics over the Herbrand universe of $P$~\cite{lloyd1987foundations}.

%------------------------------------------------------------------------------
\subsection{GLP: Extending LP with Readers}
\label{sec:glp-ext}
%------------------------------------------------------------------------------

Grassroots Logic Programs (GLP) extend LP by (1) adding a paired \emph{reader} $X?$ to every ``ordinary'' logic variable $X$, now called a \emph{writer}; (2) restricting variables in goals and clauses to have at most a single occurrence (SO); and (3) requiring that a variable occurs in a clause iff its paired variable also occurs in it (single-reader single-writer, SRSW). The result eschews unification in favour of simple term matching, is linear-logic-like~\cite{girard1987linear}, and is futures/promises-like~\cite{friedman1976impact}: each assignment $X := T$ is produced at most once via the sole occurrence of a writer (promise) $X$, and consumed at most once via the sole occurrence of its paired reader (future) $X?$.

\begin{definition}[GLP Variables]
\label{def:glp-variables}
Recall that $\calV$ is the set of LP variables, henceforth called \temph{writers}. Define $\calV? = \{X? \mid X \in \calV\}$, called \temph{readers}. The set of all GLP variables is $\hat\calV = \calV \cup \calV?$. A writer $X$ and its reader $X?$ form a \temph{variable pair}.
\end{definition}

GLP terms, unit goals, goals, and clauses are as in LP (Definition~\ref{def:lp-syntax}) but defined over the variables in $\hat\calV$.

\begin{definition}[Single-Occurrence (SO) Invariant]
\label{def:so-invariant}
A term, goal, or clause satisfies the \temph{single-occurrence (SO) invariant} if every variable occurs in it at most once.
\end{definition}

\begin{definition}[GLP Program]
\label{def:glp-program}
A clause $C$ satisfies the \temph{single-reader/single-writer (SRSW) restriction} if it satisfies SO and a variable occurs in $C$ iff its paired variable also occurs in $C$.
A \temph{GLP program} is a finite set of clauses satisfying SRSW; clauses for the same predicate form a \temph{procedure}.
Let $\hat\calG(P)$ denote the set of goals over $\hat\calV$ and the vocabulary of $P$.
\end{definition}

\begin{example}[Fair Merge]
\label{ex:merge}
Consider the quintessential concurrent logic program for fairly merging two streams, written in GLP:
\begin{verbatim}
merge([X|Xs], Ys, [X?|Zs?]) :- merge(Ys?, Xs?, Zs).
merge(Xs, [Y|Ys], [Y?|Zs?]) :- merge(Xs?, Ys?, Zs).
merge(Xs, [], Xs?).
merge([], Ys, Ys?).
\end{verbatim}
and the goal \verb=merge([1,2,3|Xs?],[a,b|Ys?],Zs)=. Both the goal and each clause satisfy SO, and each clause satisfies SRSW. The first two clauses swap inputs in recursive calls, ensuring fairness when both streams are available.
\end{example}

As we shall see (Proposition~\ref{prop:so-preservation}), the SO invariant is maintained by the SRSW restriction: reducing a goal satisfying SO with a clause satisfying SRSW results in a goal satisfying SO. The purpose of the SRSW restriction is to prevent multiple writer occurrences racing to bind a variable.

%------------------------------------------------------------------------------
\subsection{GLP Operational Semantics}
\label{sec:glp-operational}
%------------------------------------------------------------------------------

\begin{definition}[Writers Substitution, Assignment, Readers Substitution and Counterpart]
\label{def:writers-assignment}
A GLP \temph{writer assignment} is a term of the form $X := T$, $X\in\calV$, $T\notin\calV$, satisfying SO. Similarly, a GLP \temph{reader assignment} is a term of the form $X? := T$, $X?\in\calV?$, $T\notin\calV$, satisfying SO. A \temph{writers (readers) substitution} $\sigma$ is the substitution implied by a set of writer (reader) assignments that jointly satisfy SO. Given a writers assignment $X := T$, its \temph{readers counterpart} is $X? := T$, and given a writers substitution $\sigma$, its \temph{readers counterpart} $\sigma?$ is the readers substitution defined by $X?\sigma? = X\sigma$.
\end{definition}

\begin{definition}[GLP Renaming, Renaming Apart]
\label{def:glp-renaming}
A \temph{GLP renaming} is a substitution $\rho: \hat\calV \to \hat\calV$ such that for each $X \in \calV$: $X\rho \in \calV$ and $X?\rho = (X\rho)?$. Two GLP terms \temph{have a variable in common} if for some writer $X \in \calV$, either $X$ or $X?$ occurs in both. A GLP renaming $\sigma$ \temph{renames $T'$ apart from} $T$ if $T'\sigma$ and $T$ have no variable in common.
\end{definition}

\begin{definition}[Writer MGU]
\label{def:writer-mgu}
Given two GLP unit goals $A$ and $H$, a \temph{writer mgu} is a writers substitution $\sigma$ such that $A\sigma = H\sigma$ and $\sigma$ is most general among such substitutions. Unlike standard unification, writer mgu only binds writers, not readers.
\end{definition}

\begin{definition}[GLP Goal/Clause Reduction]
\label{def:glp-reduction}
Given GLP unit goal $A$ and clause $C$, with $H$ \verb|:-| $B$ being the result of the GLP renaming of $C$ apart from $A$, the \temph{GLP reduction} of $A$ with $C$ \temph{succeeds with result} $(B,\sigma)$ if $A$ and $H$ have a writer mgu.
\end{definition}

\begin{definition}[GLP Transition System]
\label{def:glp-ts}
Given a GLP program $P$, an \temph{asynchronous resolvent} over $P$ is a pair $(G, \sigma)$ where $G \in \hat\calG(P)$ and $\sigma$ is a readers substitution.

A transition system $GLP(P) = (\calC, c_0, \calT)$ is a \temph{GLP transition system} over $P$ and initial goal $G_0$ satisfying SO if:
\begin{enumerate}
    \item $\calC$ is the set of all asynchronous resolvents over $P$
    \item $c_0 = (G_0, \emptyset)$
    \item $\calT$ is the set of all transitions $(G, \sigma) \rightarrow (G', \sigma')$ satisfying either:
    \begin{enumerate}
        \item \textbf{Reduce:} there exists unit goal $A \in G$ such that $C \in P$ is the first clause for which the GLP reduction of $A$ with $C$ succeeds with result $(B, \hat\sigma)$, $G' = (G \setminus \{A\} \cup B)\hat\sigma$, and $\sigma' = \sigma \circ \hat\sigma?$
        \item \textbf{Communicate:} $\{X? := T\} \in \sigma$, $X?\in G$, $G' = G\{X? := T\}$, and $\sigma' = \sigma$
    \end{enumerate}
\end{enumerate}
\end{definition}

GLP Reduce differs from LP in (1) the use of a writer mgu instead of a regular mgu and (2) the choice of the first applicable clause instead of any clause. The first is the fundamental use of GLP readers for synchronization. The second compromises on the or-nondeterminism of LP to allow writing fair concurrent programs, such as fair merge above. Note that or-nondeterminism is not completely eliminated, as different scheduling of arrival of bindings on the two input streams of \verb|merge| may result in different orders in its output stream.

The GLP Communicate rule realizes the use of reader/writer pairs for asynchronous communication: it communicates an assignment from its writer to its paired reader.


\mypara{Monotonicity}
Key differences between LP and GLP relate to monotonicity. In LP, if a goal cannot be reduced, it will never be reduced. In GLP, a goal that cannot be reduced now may be reduced in the future: if $A$ and $H$ have an mgu that writes on a reader $X? \in A$, and therefore have no writer mgu at present,  another goal that has $X$ may reduce, assigning $X$, and later $X?$, to a value that will allow $A$ and $H$ to have a writer mgu. Conversely, in LP, if a goal $A$ can be reduced now with some clause $H$\verb|:-|$B$, with a regular mgu of $A$ and $H$, it may not be reducible in the future due to variables that $A$ shares with other goals being assigned values by reductions of other goals, preventing unification between the instantiated $A$ and $H$. In GLP, if a goal $A$ can be reduced now (with a writers mgu), it can always be reduced in the future, as the SO invariant ensures that no other goal can assign any writer in $A$.

Implementation-wise, if a GLP goal $A$ cannot be reduced now, but there is a readers substitution $\sigma$ such that $A\sigma$ can be reduced, such readers are identified, the goal $A$ \emph{suspends} on these readers, and is rescheduled for another reduction attempt once any of them is assigned.

Despite these differences, GLP adopts the same notions of successful run and outcome of LP (Definition~\ref{def:proper-run}), and has the same notion of logical consequence as LP. Let $/?$ be an operator that replaces every reader by its paired writer.

\begin{proposition}[GLP Computation is Deduction]
\label{prop:glp-deduction}
Let $(G_0$ \verb|:-| $G_n)\sigma$ be the outcome of a proper GLP run $\rho: (G_0,\sigma_0) \rightarrow \cdots \rightarrow (G_n, \sigma_n)$ of $GLP(P)$. Then $(G_0$ \verb|:-| $G_n)\sigma/?$ is a logical consequence of $P/?$.
\end{proposition}

We note two additional safety properties of GLP runs.

\begin{proposition}[SO Preservation]
\label{prop:so-preservation}
If the initial goal $G_0$ satisfies SO, then every goal in the GLP run satisfies SO.
\end{proposition}

\begin{proposition}[Monotonicity]
\label{prop:glp-monotonicity}
In any GLP run, if unit goal $A$ can reduce with clause $C$ at step $i$, then either an instance of $A$ has been reduced by step $j > i$, or an instance of $A$ can still reduce with $C$ at step $j$.
\end{proposition}

\begin{lemma}[Persistence]
\label{lem:persistence}
GLP is persistent: every enabled transition remains enabled until taken. For Reduce: if a Reduce transition is enabled for goal $A$ in configuration $(G, \sigma_r)$, it remains enabled in any configuration $(G, \sigma'_r)$ with $\sigma_r \subseteq \sigma'_r$, since other Reduce transitions bind disjoint writers (by SO) and Communicate transitions only instantiate readers. For Communicate: applying $\{X? := T\} \in \sigma$ to $X? \in G$ remains enabled since Reduce transitions do not remove assignments from $\sigma$ and other Communicate transitions apply different assignments.
\end{lemma}

\begin{definition}[Fair Run]
\label{def:fair-run}
A complete GLP run is \temph{fair} if every transition that becomes enabled is eventually taken.
\end{definition}

Proofs appear in Appendix~\ref{appendix:proofs}.

%------------------------------------------------------------------------------
\subsection{Term Matching Eschews Unification}
\label{sec:term-matching}
%------------------------------------------------------------------------------

If two terms $T_1$ and $T_2$ that jointly satisfy SO are unifiable with an mgu $\sigma$, then $\sigma$ maps any variable in $T_1$ to a subterm of $T_2$ and vice versa. Hence, the SO invariant of GLP allows eschewing unification in favour of \emph{term matching} that performs joint term-tree traversal and collects variable assignments along the way.

\begin{definition}[Term Matching]
\label{def:term-matching}
Given two terms $T_1$ and $T_2$ that jointly satisfy SO, their \temph{term matching} proceeds via the joint traversal of the term-trees of $T_1$ and $T_2$, consulting the following table at each pair of joint vertices, where $X_1, X_2$ denote writers, $X_1?, X_2?$ denote readers, and $f/n$ denotes a non-variable term, a constant when $n=0$ and a compound term when $n>0$:
\begin{center}
\begin{tabular}{l|lll}
$T_1 \backslash T_2$ & Writer $X_2$ & Reader $X_2?$ & Term $f_2/n_2$ \\
\hline
Writer $X_1$ & fail & $X_1 := X_2?$ & $X_1 := T_2$ \\
Reader $X_1?$ & $X_2 := X_1?$ & fail & suspend on $X_1?$\\
Term $f_1/n_1$ & $X_2 := T_1$ & fail & fail if $f_1 \ne f_2$ or $n_1 \ne n_2$\\
\end{tabular}
\end{center}
The writer mgu is the union of all writer assignments if no \emph{fail} was encountered and the suspension set is empty.
\end{definition}

\begin{remark}
In an actual implementation, assuming $T_1$ is a goal term and $T_2$ a head term, the case of $X_1?$ and $T_2$ would add $X_1?$ to the set of readers the goal would suspend upon.
\end{remark}

%------------------------------------------------------------------------------
\subsection{Guards}
\label{sec:guards}
%------------------------------------------------------------------------------

GLP clauses may include \emph{guards}---tests that determine clause applicability.

\begin{definition}[Guarded Clause]
\label{def:guarded-clause}
A \temph{guarded clause} has the form $H$ \verb|:-| $G$ \verb"|" $B$, where $H$ is the head, $G$ is a conjunction of guard predicates, and $B$ is the body. The guard separator ``\verb"|"'' distinguishes guards from the body, and is interpreted logically as a conjunction.  Guard arguments are readers paired to head writers.
\end{definition}

Guards have three-valued semantics. Each guard predicate explicitly defines its \emph{success} condition. A guard \emph{suspends} if it does not succeed but some instance of it under a readers substitution would succeed. A guard \emph{fails} if no such instance exists. A guard conjunction succeeds if all members succeed; it suspends if any member suspends and none fail; it fails if any member fails.

Definition~\ref{def:glp-reduction} of a GLP goal/clause reduction is augmented to succeed if the guard also succeeds.

\begin{remark}[Guards and SRSW]
\label{rem:guards-srsw}
Guard occurrences count toward SRSW satisfaction: if $X?$ occurs in a guard, its paired writer $X$ must occur in the head and $X?$ may additionally occur once in the body.

Furthermore, if the success of a guard implies that $X?$ is ground, then $X?$ as well as $X$ may occur multiple times in the clause. Groundness-implying guards include \verb|ground|, \verb|integer|, \verb|number|, \verb|string|, \verb|constant|, arithmetic comparisons (\verb|<|, \verb|>|, \verb|=<|, \verb|>=|, \verb|=:=|, \verb|=\=|), and ground equality (\verb|=?=|). However,  \verb|known| and \verb|compound| do not imply groundness.
\end{remark}

\begin{remark}[Anonymous Variables]
\label{rem:anonymous-variables}
An \emph{anonymous variable} is any variable whose name begins with \verb|_| (e.g., \verb|_|, \verb|_In?|, \verb|_Out|). Anonymous writers may appear in the head, denoting a fresh writer with no paired reader, so that a value assigned to it is discarded. This provides a controlled exception to the SRSW restriction, allowing a process to abandon an input (e.g.\ an input stream) they are no longer interested in.
\end{remark}

Guard predicates include type tests (\verb|integer|, \verb|number|, \verb|string|, \verb|constant|, \verb|compound|, \verb|ground|, \verb|known|), arithmetic comparisons (\verb|<|, \verb|>|, \verb|=<|, \verb|>=|, \verb|=:=|, \verb|=\=|), and ground equality (\verb|=?=|).

%------------------------------------------------------------------------------
\subsection{Programming Examples}
\label{sec:examples}
%------------------------------------------------------------------------------

\begin{example}[Stream Distribution]
\label{ex:distribute}
Broadcasting to multiple consumers uses the \verb|ground| guard to enable safe replication:
\begin{verbatim}
distribute([X|Xs], [X?|Ys1?], [X?|Ys2?]) :- ground(X?) |
    distribute(Xs?, Ys1, Ys2).
distribute([], [], []).
\end{verbatim}
Since \verb|X?| is ground, its multiple occurrences in the head do not violate SRSW.
\end{example}

\begin{example}[Lookup in Association List]
\label{ex:lookup}
\begin{verbatim}
lookup(Key, [(K, Value)|_], Value?) :- Key? =?= K? | true.
lookup(Key, [_|Rest], Value?) :- otherwise | lookup(Key?, Rest?, Value).
\end{verbatim}
The \verb|=?=| guard tests ground equality; \verb|otherwise| succeeds when no prior clause applies.
\end{example}

%------------------------------------------------------------------------------
\subsection{The Grassroots Social Graph}
\label{sec:social-graph}
%------------------------------------------------------------------------------

The grassroots social graph is the foundational platform upon which all other grassroots platforms are built. Nodes represent cryptographically-identified agents; edges represent authenticated bidirectional channels; connected components arise spontaneously through befriending.

We present the social graph as a single-agent GLP program, using a \emph{network switch} to simulate communication between agents. This demonstrates the program structure before introducing multiagent GLP in Section~\ref{sec:maglp}. We illustrate with a comprehensive scenario involving three agents---Alice, Bob, and Charlie---that demonstrates cold-call befriending, text messaging, and friend-mediated introduction. The complete program appears in Appendix~\ref{appendix:social-graph-complete}.

\subsubsection{Types and Channels}

The social graph uses the following type definitions:
\begin{verbatim}
Response ::= accept(Channel) ; no.
FriendEntry ::= friend(String, Stream?).
FriendsList ::= [] ; [FriendEntry|FriendsList].
\end{verbatim}

A \verb|Channel| is a pair of streams for bidirectional communication. The \verb|new_channel| guard creates complementary channel endpoints:
\begin{verbatim}
new_channel(ch(Xs?, Ys), ch(Ys?, Xs)).
\end{verbatim}
Both endpoints read from their first stream and write to their second:
The first  reads from \verb|Xs?| and writes to \verb|Ys|; the second reads from \verb|Ys?| and writes to \verb|Xs|.

\subsubsection{Agent Structure}

Each agent processes messages from a unified input stream, maintaining a friends list that maps names to output streams:
\begin{verbatim}
agent_init(Id, ch(UserIn, UserOut?), ch(NetIn, NetOut?)) :-
    merge(UserIn?, NetIn?, In),
    agent(Id?, In?, [friend(user, UserOut), friend(net, NetOut)]).
\end{verbatim}
The agent merges user and network input streams, then enters the main event loop \verb|agent| with the agent's identity, merged input, and initial friends list containing channels to the user interface and network.

\subsubsection{Cold-Call Befriending Protocol}

The cold-call protocol enables agents to establish friendship without prior shared variables. Figure~\ref{fig:cold-call} shows the protocol clauses.

\begin{figure*}[t]
\begin{verbatim}
%% User initiates cold call (2-arg network message)
agent(Id, [msg(user, Id1, connect(Target))|In], Fs) :-
    Id? =?= Id1?, ground(Target?) |
    lookup_send(net, msg(Target?, intro(Id?, Resp)), Fs?, Fs1),
    inject_msg(Resp?, Target?, Id?, In?, In1),
    agent(Id?, In1?, Fs1?).

%% Received cold-call introduction (2-arg msg, 2-arg intro)
agent(Id, [msg(Id1, intro(From, Resp))|In], Fs) :-
    Id? =?= Id1? |
    lookup_send(user, msg(agent, user, befriend(From?, Resp?)), Fs?, Fs1),
    agent(Id?, In?, Fs1?).

%% User decision on cold-call
agent(Id, [msg(user, Id1, decision(Dec, From, Resp?))|In], Fs) :-
    Id? =?= Id1? |
    bind_response(Dec?, From?, Resp, Fs?, Fs1, In?, In1),
    agent(Id?, In1?, Fs1?).

%% Response to sent cold-call
agent(Id, [msg(From, Id1, response(Resp))|In], Fs) :-
    Id? =?= Id1? |
    handle_response(Resp?, From?, Fs?, Fs1, In?, In1),
    agent(Id?, In1?, Fs1?).
\end{verbatim}
\caption{Cold-call befriending protocol}
\label{fig:cold-call}
\end{figure*}

The protocol works as follows: (1) Alice sends \verb|connect(bob)| to her agent; (2) her agent sends a 2-argument \verb|msg(bob, intro(alice, Resp))| via the network, including a fresh response variable \verb|Resp|; (3) Bob receives \verb|msg(bob, intro(alice, Resp))| and forwards the request to his user interface; (4) Bob decides \verb|yes| or \verb|no|; (5) Bob's agent creates a channel pair and sends \verb|accept(Ch)| back via \verb|Resp|; (6) Alice's agent receives the response and both agents add each other to their friends lists.

\subsubsection{Channel Establishment}

When a cold-call is accepted, both agents establish symmetric channels (Figure~\ref{fig:channel-establish}).

\begin{figure*}[t]
\begin{verbatim}
bind_response(yes, From, accept(RetCh?), Fs, Fs1?, In, In1?) :-
    new_channel(RetCh, LocalCh) |
    handle_response(accept(LocalCh?), From?, Fs?, Fs1, In?, In1).
bind_response(no, _, no, Fs, Fs?, In, In?).

handle_response(accept(ch(FIn, FOut?)), From, Fs, Fs1?, In, In1?) :-
    ground(From?) |
    merge(In?, FIn?, In1),
    add_friend_and_notify(From?, FOut, Fs?, Fs1).
handle_response(no, From, Fs, Fs1?, In, In?) :-
    ground(From?) |
    lookup_send(user, msg(agent, user, rejected(From?)), Fs?, Fs1).
\end{verbatim}
\caption{Channel establishment}
\label{fig:channel-establish}
\end{figure*}

The accepting agent creates a channel pair via \verb|new_channel(RetCh, LocalCh)|. It sends \verb|RetCh| back to the initiator and keeps \verb|LocalCh| for itself. Both channels are complementary: each agent's input is the other's output.

\subsubsection{Text Messaging}

Once agents are friends, they can exchange text messages (Figure~\ref{fig:messaging}).

\begin{figure*}[t]
\begin{multicols}{2}
\begin{verbatim}
%% User sends text message to friend
agent(Id,
  [msg(user, Id1,
       send(Target, Text))|In],
  Fs) :-
    Id? =?= Id1?, ground(Target?) |
    lookup_send(Target?,
      msg(Id?, Target?, text(Text?)),
      Fs?, Fs1),
    agent(Id?, In?, Fs1?).
\end{verbatim}
\columnbreak
\begin{verbatim}
%% Received text message from friend
agent(Id,
  [msg(From, Id1, text(Text))|In],
  Fs) :-
    Id? =?= Id1? |
    lookup_send(user,
      msg(agent, user,
          received(From?, Text?)),
      Fs?, Fs1),
    agent(Id?, In?, Fs1?).
\end{verbatim}
\end{multicols}
\caption{Text messaging between friends}
\label{fig:messaging}
\end{figure*}

\subsubsection{Friend-Mediated Introduction}

Once agents are friends, they can introduce each other to third parties. The introducer creates a fresh channel pair and sends each half to the respective parties (Figure~\ref{fig:friend-intro}).

\begin{figure*}[t]
\begin{multicols}{2}
\begin{verbatim}
%% User commands: introduce P to Q
agent(Id,
  [msg(user, Id1, introduce(P, Q))|In],
  Fs) :-
    Id? =?= Id1?, ground(P?),
    ground(Q?),
    new_channel(PQCh, QPCh) |
    lookup_send(P?,
      msg(Id?, P?, intro(Q?, QPCh?)),
      Fs?, Fs1),
    lookup_send(Q?,
      msg(Id?, Q?, intro(P?, PQCh?)),
      Fs1?, Fs2),
    agent(Id?, In?, Fs2?).
\end{verbatim}
\columnbreak
\begin{verbatim}
%% Received introduction from friend
agent(Id,
  [msg(From, Id1, intro(Other, Ch))|In],
  Fs) :-
    Id? =?= Id1?, ground(Other?) |
    lookup_send(user,
      msg(agent, user,
          befriend_intro(
            From?, Other?, Ch?)),
      Fs?, Fs1),
    agent(Id?, In?, Fs1?).

%% User accepts friend introduction
agent(Id,
  [msg(user, Id1,
       accept_intro(Other, Ch))|In],
  Fs) :-
    Id? =?= Id1?, ground(Other?) |
    handle_intro_accept(Ch?, Other?,
      Fs?, Fs1, In?, In1),
    agent(Id?, In1?, Fs1?).
\end{verbatim}
\end{multicols}
\caption{Friend-mediated introduction protocol}
\label{fig:friend-intro}
\end{figure*}

When Bob types \verb|introduce(alice, charlie)|, he creates a channel pair via \verb|new_channel(PQCh, QPCh)|. Alice receives \verb|ch(QtoP?, PtoQ)|---she reads from Charlie via \verb|QtoP?| and writes to Charlie via \verb|PtoQ|. Charlie receives the complementary \verb|ch(PtoQ?, QtoP)|. When both accept, they become direct friends without Bob's further involvement.

Note the distinction between cold-call messages and friend-mediated messages: cold-call uses a 2-argument \verb|msg(Target, intro(From, Resp))| sent via the network, while friend-mediated introduction uses a 3-argument \verb|msg(From, To, intro(Other, Ch))| sent directly to a friend.

\subsubsection{Network Switch Simulation}

In deployment, agents communicate through a physical network. In simulation, a \verb|network3| process routes messages between three agents (Figure~\ref{fig:network-switch}).

\begin{figure*}[t]
\begin{multicols}{2}
\begin{verbatim}
procedure network3(
  Channel?, Channel?, Channel?).

%% Alice -> Bob (2-arg cold-call msg)
network3(
  ch([msg(bob, X)|AliceIn],
     AliceOut?),
  ch(BobIn,
     [msg(bob, X?)|BobOut?]),
  ch(CharlieIn, CharlieOut?)) :-
    network3(
      ch(AliceIn?, AliceOut),
      ch(BobIn?, BobOut),
      ch(CharlieIn?, CharlieOut)).

%% Bob -> Charlie
network3(
  ch(AliceIn, AliceOut?),
  ch([msg(charlie, X)|BobIn],
     BobOut?),
  ch(CharlieIn,
     [msg(charlie, X?)
      |CharlieOut?])) :-
    network3(
      ch(AliceIn?, AliceOut),
      ch(BobIn?, BobOut),
      ch(CharlieIn?, CharlieOut)).
\end{verbatim}
\columnbreak
\begin{verbatim}
%% Alice -> Charlie
network3(
  ch([msg(charlie, X)|AliceIn],
     AliceOut?),
  ch(BobIn, BobOut?),
  ch(CharlieIn,
     [msg(charlie, X?)
      |CharlieOut?])) :-
    network3(
      ch(AliceIn?, AliceOut),
      ch(BobIn?, BobOut),
      ch(CharlieIn?, CharlieOut)).

%% (Three more clauses for:
%%  Bob->Alice, Charlie->Alice,
%%  Charlie->Bob)

%% Termination
network3(
  ch([], []),
  ch([], []),
  ch([], [])).
\end{verbatim}
\end{multicols}
\caption{Network switch simulation for three agents}
\label{fig:network-switch}
\end{figure*}

The network switch simulates the Cold-call transaction introduced in Section~\ref{sec:maglp}.

\subsubsection{The Scenario and Actors}

The complete scenario demonstrates all three protocols:
\begin{enumerate}
\item Alice cold-calls Bob (Bob accepts) --- Alice and Bob become friends
\item Alice sends Bob: ``Hi Bob, this is Alice''
\item Bob cold-calls Charlie (Charlie accepts) --- Bob and Charlie become friends
\item Charlie sends Bob: ``Hi Bob, this is Charlie''
\item Bob introduces Alice to Charlie (both accept) --- Alice and Charlie become direct friends
\item Alice sends Charlie: ``Hi Charlie, this is Alice''
\item Charlie responds: ``Hi Alice, this is Charlie''
\end{enumerate}

Each agent is driven by an \emph{actor}---a GLP procedure that implements a state machine, reacting to messages from the agent and producing commands. The actor's state is encoded in procedure names (e.g., \verb|alice_wait_bob_connected|, \verb|bob_wait_charlie_msg|), with transitions via recursive calls. See Appendix~\ref{appendix:social-graph-complete} for the complete actor implementations and the play that ties everything together.
